{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=float:right><img src=\"assets/img/appliedai-logo.png\" width=100 style=\"margin: 0px 20px\"></img></div>\n",
    "\n",
    "\n",
    "##### Jonathan Sedar Personal Project\n",
    "## PyMC3 vs PyStan Comparison\n",
    "_Spring 2016_\n",
    "\n",
    "This set of Notebooks and scripts comprise the **pymc3_vs_pystan** personal project by Jonathan Sedar of Applied AI Ltd, written primarily for presentation at the PyData London 2016 Conference.\n",
    "\n",
    "The project demonstrates hierarchical linear regression using two Bayesian inference frameworks: PyMC3 and PyStan. The project borrows heavily from code written for Applied AI Ltd and is supplied here for educational purposes only. No copyright or license is extended to users.\n",
    "\n",
    "\n",
    "    \n",
    "# 31_BasicModelEvaluation\n",
    "\n",
    "#### Demonstrate posterior predictive checks and info criteria\n",
    "\n",
    "      \n",
    "+ [Setup](#Setup)\n",
    "    + [Local Functions](#Local-Functions)\n",
    "    + [Load Data](#Load-Data)\n",
    "    + [Prepare Dataset](#Prepare-Dataset)\n",
    "\n",
    "\n",
    "+ [Posterior Predictive Checks on Training Data](#Posterior-Predictive-Checks-on-Training-Data)\n",
    "    + [Eyeballing](#Eyeballing)\n",
    "    + [MSE and R-squared](#MSE-and-R-squared)\n",
    "    + [KS test](#KS-test)  \n",
    "    \n",
    "\n",
    "+ [Posterior Predictive Checks on Validation Data](#Posterior-Predictive-Checks-on-Validation-Data)\n",
    "    + [Held-out test set](#Held-out-test-set)\n",
    "    + [Cross-Validation](#Cross-Validation)\n",
    "    + [Leave-One-Out Cross-Val](#Leave-One-Out-Cross-Val)\n",
    "\n",
    "\n",
    "+ [Information Criteria](#Information-Criteria)\n",
    "    + [Deviance Information Criterion](Deviance-Information-Criterion)  \n",
    "    + [Widely-Accepted Information Criterion](#Widely-Accepted-Information-Criterion)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:\n",
    "\n",
    "For more information on Model Selection in PyMC3, and about DIC and WAIC, you could start with:\n",
    "+ Thomas Wiecki's [detailed response](https://stats.stackexchange.com/questions/161082/bayesian-model-selection-in-pymc3/166383#166383) to a question on Cross Validated\n",
    "+ The Deviance Information Criterion: 12 Years On ([Speigelhalter et al 2014](http://onlinelibrary.wiley.com/doi/10.1111/rssb.12062/abstract))\n",
    "+ A Widely Applicable Bayesian Information Criterion ([Watanabe 2013](http://www.jmlr.org/papers/volume14/watanabe13a/watanabe13a.pdf))\n",
    "+ Efficient Implementation of Leave-One-Out Cross-Validation and WAIC for Evaluating Fitted Bayesian Models ([Gelman et al 2015](http://arxiv.org/abs/1507.04544))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Interactive magics\n",
    "%matplotlib inline\n",
    "%qtconsole --colors=linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# general packages\n",
    "import sqlite3\n",
    "from convenience_functions import *\n",
    "from ipywidgets import interactive, fixed\n",
    "#from io import StringIO\n",
    "#from collections import OrderedDict\n",
    "#from itertools import combinations\n",
    "\n",
    "# scientific packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import patsy as pt\n",
    "from scipy import optimize\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "#from sklearn.neighbors.kde import KernelDensity\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# pymc3 libraries\n",
    "import pymc3 as pm\n",
    "import theano as thno\n",
    "import theano.tensor as T \n",
    "import pystan\n",
    "\n",
    "sns.set(style=\"darkgrid\", palette=\"muted\")\n",
    "pd.set_option('display.mpl_style', 'default')\n",
    "plt.rcParams['figure.figsize'] = 12, 4\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip_derived_rvs(rvs):\n",
    "    '''Convenience fn: remove PyMC3-generated RVs from a list'''\n",
    "    ret_rvs = []\n",
    "    for rv in rvs:\n",
    "        if not (re.search('_log',rv.name) or re.search('_interval',rv.name)):\n",
    "            ret_rvs.append(rv)     \n",
    "    return ret_rvs\n",
    "\n",
    "\n",
    "def trace_median(x):\n",
    "    return pd.Series(np.median(x,0), name='median')\n",
    "\n",
    "\n",
    "def plot_traces_pymc(trcs, varnames=None):\n",
    "    ''' Convenience fn: plot traces with overlaid means and values '''\n",
    "\n",
    "    nrows = len(trcs.varnames)\n",
    "    if varnames is not None:\n",
    "        nrows = len(varnames)\n",
    "    ax = pm.traceplot(trcs, varnames=varnames, figsize=(12,nrows*1.4)\n",
    "        ,lines={k: v['mean'] for k, v in \n",
    "            pm.df_summary(trcs,varnames=varnames).iterrows()})\n",
    "\n",
    "    for i, mn in enumerate(pm.df_summary(trcs, varnames=varnames)['mean']):\n",
    "        ax[i,0].annotate('{:.2f}'.format(mn), xy=(mn,0), xycoords='data'\n",
    "                    ,xytext=(5,10), textcoords='offset points', rotation=90\n",
    "                    ,va='bottom', fontsize='large', color='#AA0022')    \n",
    "\n",
    "        \n",
    "def plot_stan_trc(dftrc):\n",
    "    \"\"\"\n",
    "       Create simple plots of parameter distributions and traces from \n",
    "       output of pystan sampling. Emulates pymc traceplots.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax2d = plt.subplots(nrows=dftrc.shape[1], ncols=2, figsize=(14, 1.8*dftrc.shape[1]),\n",
    "                                facecolor='0.99', edgecolor='k')\n",
    "    fig.suptitle('Distributions and traceplots for {} samples'.format(\n",
    "                                dftrc.shape[0]),fontsize=14)\n",
    "    fig.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "    k = 0\n",
    "    \n",
    "    # create density and traceplot, per parameter coeff\n",
    "    for i, (ax1d, col) in enumerate(zip(ax2d, dftrc.columns)):\n",
    "\n",
    "        samples = dftrc[col].values\n",
    "        scale = (10**np.round(np.log10(samples.max() - samples.min()))) / 20\n",
    "        kde = KernelDensity(bandwidth=scale).fit(samples.reshape(-1, 1))\n",
    "        x = np.linspace(samples.min(), samples.max(), 100).reshape(-1, 1)\n",
    "        y = np.exp(kde.score_samples(x))\n",
    "        clr = sns.color_palette()[0]\n",
    "\n",
    "        # density plot\n",
    "        ax1d[0].plot(x, y, color=clr, linewidth=1.4)\n",
    "        ax1d[0].vlines(np.percentile(samples, [2.5, 97.5]), ymin=0, ymax=y.max()*1.1,\n",
    "                       alpha=1, linestyles='dotted', colors=clr, linewidth=1.2)\n",
    "        mn = np.mean(samples)\n",
    "        ax1d[0].vlines(mn, ymin=0, ymax=y.max()*1.1,\n",
    "                       alpha=1, colors='r', linewidth=1.2)\n",
    "        ax1d[0].annotate('{:.2f}'.format(mn), xy=(mn,0), xycoords='data'\n",
    "                    ,xytext=(5,10), textcoords='offset points', rotation=90\n",
    "                    ,va='bottom', fontsize='large', color='#AA0022')    \n",
    "        ax1d[0].set_title('{}'.format(col), fontdict={'fontsize':10})\n",
    "\n",
    "\n",
    "        # traceplot\n",
    "        ax1d[1].plot(np.arange(len(samples)),samples, alpha=0.2, color=clr, linestyle='solid'\n",
    "                              ,marker=',', markerfacecolor=clr, markersize=10)\n",
    "        ax1d[1].hlines(np.percentile(samples,[2.5, 97.5]), xmin=0, xmax=len(samples),\n",
    "                       alpha=1, linestyles='dotted', colors=clr)\n",
    "        ax1d[1].hlines(np.mean(samples), xmin=0, xmax=len(samples), alpha=1, colors='r')\n",
    "\n",
    "        k += 1\n",
    "                \n",
    "        ax1d[0].set_title('{}'.format(col), fontdict={'fontsize':14})#,'fontweight':'bold'})\n",
    "        #ax1d[0].legend(loc='best', shadow=True)\n",
    "        \n",
    "        _ = [ax1d[j].axes.grid(True, linestyle='-', color='lightgrey') for j in range(2)]\n",
    "            \n",
    "    plt.subplots_adjust(top=0.94)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnxsql = sqlite3.connect('data/car_emissions.db')\n",
    "dfs = pd.read_sql('select * from cars_post_exclusions_2sd', cnxsql, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert sqlite bool storage (as ints) back to bools\n",
    "for ft in ['parent_is_vw', 'mfr_is_vw', 'is_tdi']:\n",
    "    dfs[ft] = dfs[ft].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2593, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1653</th>\n",
       "      <th>835</th>\n",
       "      <th>763</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>emissions_nox_mgkm</th>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>2593</td>\n",
       "      <td>37.32</td>\n",
       "      <td>17.9</td>\n",
       "      <td>1</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parent_is_vw</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mfr_is_vw</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parent</th>\n",
       "      <td>daimler-ag</td>\n",
       "      <td>bmw</td>\n",
       "      <td>bmw</td>\n",
       "      <td>2593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>volksw</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mfr</th>\n",
       "      <td>mercedes-benz</td>\n",
       "      <td>bmw</td>\n",
       "      <td>bmw</td>\n",
       "      <td>2593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abarth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>volvo</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans</th>\n",
       "      <td>auto</td>\n",
       "      <td>semiauto</td>\n",
       "      <td>auto</td>\n",
       "      <td>2593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>semiau</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuel_type</th>\n",
       "      <td>petrol</td>\n",
       "      <td>petrol</td>\n",
       "      <td>petrol</td>\n",
       "      <td>2593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>diesel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>petrol</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_tdi</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric_combined</th>\n",
       "      <td>-0.0728208</td>\n",
       "      <td>0.80692</td>\n",
       "      <td>0.220426</td>\n",
       "      <td>2593</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.685973</td>\n",
       "      <td>-0.339409</td>\n",
       "      <td>-0.152797</td>\n",
       "      <td>0.167108</td>\n",
       "      <td>2.75301</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric_extra_urban</th>\n",
       "      <td>-0.0751821</td>\n",
       "      <td>0.47462</td>\n",
       "      <td>0.0728415</td>\n",
       "      <td>2593</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.47696</td>\n",
       "      <td>-0.180913</td>\n",
       "      <td>-0.075182</td>\n",
       "      <td>0.093988</td>\n",
       "      <td>21.5997</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric_urban_cold</th>\n",
       "      <td>-0.0249258</td>\n",
       "      <td>0.724487</td>\n",
       "      <td>0.291493</td>\n",
       "      <td>2593</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.657763</td>\n",
       "      <td>-0.308037</td>\n",
       "      <td>-0.158155</td>\n",
       "      <td>0.158264</td>\n",
       "      <td>2.92276</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine_capacity</th>\n",
       "      <td>-0.259591</td>\n",
       "      <td>0.502214</td>\n",
       "      <td>-0.0383156</td>\n",
       "      <td>2593</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.920116</td>\n",
       "      <td>-0.278857</td>\n",
       "      <td>-0.045471</td>\n",
       "      <td>-0.037765</td>\n",
       "      <td>2.57901</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emissions_co_mgkm</th>\n",
       "      <td>-0.325803</td>\n",
       "      <td>-0.456874</td>\n",
       "      <td>0.0567836</td>\n",
       "      <td>2593</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.846545</td>\n",
       "      <td>-0.382482</td>\n",
       "      <td>-0.088458</td>\n",
       "      <td>0.272874</td>\n",
       "      <td>2.28145</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             1653       835        763  count   mean   std  \\\n",
       "emissions_nox_mgkm             12        36         32   2593  37.32  17.9   \n",
       "parent_is_vw                False     False      False   2593    NaN   NaN   \n",
       "mfr_is_vw                   False     False      False   2593    NaN   NaN   \n",
       "parent                 daimler-ag       bmw        bmw   2593    NaN   NaN   \n",
       "mfr                 mercedes-benz       bmw        bmw   2593    NaN   NaN   \n",
       "trans                        auto  semiauto       auto   2593    NaN   NaN   \n",
       "fuel_type                  petrol    petrol     petrol   2593    NaN   NaN   \n",
       "is_tdi                      False     False      False   2593    NaN   NaN   \n",
       "metric_combined        -0.0728208   0.80692   0.220426   2593  -0.00   0.5   \n",
       "metric_extra_urban     -0.0751821   0.47462  0.0728415   2593   0.00   0.5   \n",
       "metric_urban_cold      -0.0249258  0.724487   0.291493   2593   0.00   0.5   \n",
       "engine_capacity         -0.259591  0.502214 -0.0383156   2593   0.00   0.5   \n",
       "emissions_co_mgkm       -0.325803 -0.456874  0.0567836   2593   0.00   0.5   \n",
       "\n",
       "                         min        25%        50%        75%      max  \\\n",
       "emissions_nox_mgkm         1  23.000000  35.000000  51.000000       76   \n",
       "parent_is_vw           False        NaN        NaN        NaN     True   \n",
       "mfr_is_vw              False        NaN        NaN        NaN     True   \n",
       "parent                aston         NaN        NaN        NaN   volksw   \n",
       "mfr                   abarth        NaN        NaN        NaN    volvo   \n",
       "trans                   auto        NaN        NaN        NaN   semiau   \n",
       "fuel_type             diesel        NaN        NaN        NaN   petrol   \n",
       "is_tdi                 False        NaN        NaN        NaN     True   \n",
       "metric_combined    -0.685973  -0.339409  -0.152797   0.167108  2.75301   \n",
       "metric_extra_urban  -0.47696  -0.180913  -0.075182   0.093988  21.5997   \n",
       "metric_urban_cold  -0.657763  -0.308037  -0.158155   0.158264  2.92276   \n",
       "engine_capacity    -0.920116  -0.278857  -0.045471  -0.037765  2.57901   \n",
       "emissions_co_mgkm  -0.846545  -0.382482  -0.088458   0.272874  2.28145   \n",
       "\n",
       "                      dtype  \n",
       "emissions_nox_mgkm  float64  \n",
       "parent_is_vw           bool  \n",
       "mfr_is_vw              bool  \n",
       "parent               object  \n",
       "mfr                  object  \n",
       "trans                object  \n",
       "fuel_type            object  \n",
       "is_tdi                 bool  \n",
       "metric_combined     float64  \n",
       "metric_extra_urban  float64  \n",
       "metric_urban_cold   float64  \n",
       "engine_capacity     float64  \n",
       "emissions_co_mgkm   float64  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_describe(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Declare feats for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fts_cat = ['parent_is_vw', 'mfr_is_vw', 'parent', 'mfr', 'trans', 'fuel_type', 'is_tdi']\n",
    "fts_cat_smp = ['mfr_is_vw','trans','fuel_type','is_tdi']\n",
    "fts_num = ['metric_combined', 'metric_extra_urban', 'metric_urban_cold'\n",
    "           ,'engine_capacity', 'emissions_co_mgkm']\n",
    "fts_num_smp = ['metric_combined', 'engine_capacity', 'emissions_co_mgkm']\n",
    "ft_endog = 'emissions_nox_mgkm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe dataset\n",
    "\n",
    "+ The dataset is 2593 rows, with 12 exog features, 1 endog feature.\n",
    "+ These are observations of car emissions tests, one row per car.\n",
    "+ You can read off the basic distributional statistics of the features in the table above. Numeric features have been standardized according to [Gelman's 2sd principle](http://www.stat.columbia.edu/~gelman/research/published/standardizing7.pdf).\n",
    "+ I have selected these particular 12 features to work with. Some are derivatives of original features.\n",
    "\n",
    "We have the following features to choose from:\n",
    "\n",
    "```\n",
    "+ Categoricals:\n",
    "    + `trans`     - the car transmission, simplified to 'auto', 'semiauto', 'manual'\n",
    "    + `fuel_type` - the car power supply, simplified to 'petrol', 'diesel'\n",
    "    + `parent`    - the parent company of the car manufacturer, 20 values\n",
    "    + `mfr`       - the car manufacturer, 38 values\n",
    "\n",
    "+ Booleans:\n",
    "    + `parent_is_vw` - if the parent company of the car manufacturer is Volkswagen\n",
    "    + `mfr_is_vw`    - if the car manufacturer is Volkswagen\n",
    "    + `is_tdi`       - (processed feature) if the car engine type is a turbo diesel\n",
    "    \n",
    "+ Numerics:\n",
    "    + `metric_combined`    - a score for fuel efficiency in combined driving\n",
    "    + `metric_extra_urban` - a score for fuel efficiency in an extra-urban driving\n",
    "    + `metric_urban_cold`  - a score for fuel efficiency in an urban setting, cold start\n",
    "    + `emissions_co_mgkm`  - a count of CO particulates emitted mg/km\n",
    "    \n",
    "+ Numeric endogenous feature:\n",
    "    + `emissions_nox_mgkm` - a count of NOx particulates emitted mg/km    \n",
    "```\n",
    "\n",
    "For the purposes of this Notebook, the final feature mentioned `emissions_nox_mgkm` will be used as the _endogenous_ / _dependent_ / _output_ feature of the linear models. All other features may be used as _exogenous_ / _independent_ / _input_ features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create design matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emissions_nox_mgkm ~ metric_combined + engine_capacity + emissions_co_mgkm + mfr_is_vw + trans + fuel_type + is_tdi'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fml_all = '{} ~ '.format(ft_endog) + ' + '.join(fts_num_smp + fts_cat_smp)\n",
    "fml_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2593, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>649</th>\n",
       "      <th>1344</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2593</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mfr_is_vw[T.True]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2593</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans[T.manual]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2593</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans[T.semiauto]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2593</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuel_type[T.petrol]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2593</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_tdi[T.True]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2593</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric_combined</th>\n",
       "      <td>-0.179456</td>\n",
       "      <td>-0.419385</td>\n",
       "      <td>2593</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.685973</td>\n",
       "      <td>-0.339409</td>\n",
       "      <td>-0.152797</td>\n",
       "      <td>0.167108</td>\n",
       "      <td>2.753013</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine_capacity</th>\n",
       "      <td>-0.039416</td>\n",
       "      <td>-0.369128</td>\n",
       "      <td>2593</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.920116</td>\n",
       "      <td>-0.278857</td>\n",
       "      <td>-0.045471</td>\n",
       "      <td>-0.037765</td>\n",
       "      <td>2.579014</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emissions_co_mgkm</th>\n",
       "      <td>-0.715474</td>\n",
       "      <td>-0.123882</td>\n",
       "      <td>2593</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.846545</td>\n",
       "      <td>-0.382482</td>\n",
       "      <td>-0.088458</td>\n",
       "      <td>0.272874</td>\n",
       "      <td>2.281452</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          649      1344  count  mean   std       min  \\\n",
       "Intercept            1.000000  1.000000   2593  1.00  0.00  1.000000   \n",
       "mfr_is_vw[T.True]    0.000000  0.000000   2593  0.04  0.20  0.000000   \n",
       "trans[T.manual]      0.000000  1.000000   2593  0.49  0.50  0.000000   \n",
       "trans[T.semiauto]    0.000000  0.000000   2593  0.12  0.32  0.000000   \n",
       "fuel_type[T.petrol]  0.000000  0.000000   2593  0.50  0.50  0.000000   \n",
       "is_tdi[T.True]       0.000000  0.000000   2593  0.12  0.32  0.000000   \n",
       "metric_combined     -0.179456 -0.419385   2593 -0.00  0.50 -0.685973   \n",
       "engine_capacity     -0.039416 -0.369128   2593  0.00  0.50 -0.920116   \n",
       "emissions_co_mgkm   -0.715474 -0.123882   2593  0.00  0.50 -0.846545   \n",
       "\n",
       "                          25%       50%       75%       max    dtype  \n",
       "Intercept            1.000000  1.000000  1.000000  1.000000  float64  \n",
       "mfr_is_vw[T.True]    0.000000  0.000000  0.000000  1.000000  float64  \n",
       "trans[T.manual]      0.000000  0.000000  1.000000  1.000000  float64  \n",
       "trans[T.semiauto]    0.000000  0.000000  0.000000  1.000000  float64  \n",
       "fuel_type[T.petrol]  0.000000  1.000000  1.000000  1.000000  float64  \n",
       "is_tdi[T.True]       0.000000  0.000000  0.000000  1.000000  float64  \n",
       "metric_combined     -0.339409 -0.152797  0.167108  2.753013  float64  \n",
       "engine_capacity     -0.278857 -0.045471 -0.037765  2.579014  float64  \n",
       "emissions_co_mgkm   -0.382482 -0.088458  0.272874  2.281452  float64  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mx_en, mx_ex) = pt.dmatrices(fml_all, dfs, return_type='dataframe', NA_action='raise')\n",
    "custom_describe(mx_ex, 2, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload Models and Traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload PyMC3 model and traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded object from disk at models/mdl_robust_pymc.pkl\n"
     ]
    }
   ],
   "source": [
    "with pm.Model():\n",
    "    mdl_robust_pymc = read_pickle(relnm='models/mdl_robust_pymc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load traces within model context\n",
    "with mdl_robust_pymc:\n",
    "    trc_robust_pymc = pm.backends.text.load('traces/trc_robust_pymc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alternatively, load with a ref to reloaded model\n",
    "trc_robust_pymc = pm.backends.text.load('traces/trc_robust_pymc', model=mdl_robust_pymc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload PyStan model and fitted model (contains traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded object from disk at models/mdl_robust_stan_model.pkl\n",
      "Loaded object from disk at models/mdl_robust_stan_fit.pkl\n"
     ]
    }
   ],
   "source": [
    "## load the model first, and then the fit:\n",
    "\n",
    "mdl_robust_pystan_model = read_pickle(relnm='models/mdl_robust_stan_model.pkl')\n",
    "\n",
    "mdl_robust_pystan_fit = read_pickle(relnm='models/mdl_robust_stan_fit.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior Predictive Checks on Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Posterior Samples (PyMC3 native method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feed native method with model and traces, output ppc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 s, sys: 530 ms, total: 21.4 s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "ppc_pymc = pm.sample_ppc(trc_robust_pymc[-1000:], samples=1000, \n",
    "                           model=mdl_robust_pymc, size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return is a dict of predicted values (traces * calcs * posterior * datapoints)\n",
    "\n",
    "    for each datapoint:              2593x\n",
    "        use each trace value:        1000x\n",
    "            calc the posterior         10x\n",
    "            \n",
    "    creates 10,000 estimates for each data point (25,930,000 values)\n",
    "    \n",
    "    (probably a little overkill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10, 1, 2593)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppc_pymc['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2593, 10000)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_pymc = ppc_pymc['y'].reshape(1000*10*1, 2593).T\n",
    "yhat_pymc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Posterior Samples (Remodel using Stan generated quantities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stan can generate a posteriour prob given datapoints within the modelsepc itself.\n",
    "\n",
    "Very handy, but appears to be only an option at modelling time, so I'll rerun the model from earlier, this time speccing the `generated_quantities{}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl_robustppc_stan_spec = \"\"\"\n",
    "\n",
    "    /* Spec for robust regression linear model */\n",
    "\n",
    "    data {                                 \n",
    "        int<lower=0> N;                     // count of observations\n",
    "        int<lower=0> M_ppc;                 // count of ppc samples per observation\n",
    "        int<lower=0> N_ppc;                 // count of ppc observations\n",
    "        int<lower=0> K;                     // count of exog features\n",
    "        matrix[N, K] X;                     // exog features\n",
    "        matrix[N_ppc, K] X_ppc;             // exog features for posterior pred\n",
    "        vector[N] y;                        // endog feature\n",
    "    }\n",
    "    parameters {\n",
    "        vector[K] beta;                     // exog coeffs\n",
    "        real<lower=0> sigma;                // linear model error\n",
    "    }\n",
    "    transformed parameters {}\n",
    "    model {  \n",
    "        sigma ~ cauchy(0, 10);              // explicit prior for error (half-cauchy)\n",
    "        y ~ student_t(1, X * beta, sigma);  // student-T likelihood\n",
    "    }\n",
    "    generated quantities {\n",
    "        matrix[M_ppc, N_ppc] y_ppc;\n",
    "        \n",
    "        // needs loops (the *_rng functions only support 1D reals inputs)\n",
    "        \n",
    "        for (n in 1:N_ppc)\n",
    "            for (m in 1:M_ppc)\n",
    "                y_ppc[m, n] <- student_t_rng(1, X_ppc[n] * beta, sigma);  // posterior pred\n",
    "    }\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stan_datadictppc = {}\n",
    "stan_datadictppc['N'] = mx_ex.shape[0]\n",
    "stan_datadictppc['K'] = mx_ex.shape[1]\n",
    "stan_datadictppc['X'] = mx_ex.values\n",
    "stan_datadictppc['y'] = mx_en[ft_endog].values\n",
    "\n",
    "stan_datadictppc['M_ppc'] = 10\n",
    "stan_datadictppc['N_ppc'] = mx_ex.shape[0]\n",
    "stan_datadictppc['X_ppc'] = mx_ex.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl_robustppc_stan_fit = pystan.stan(\n",
    "        model_code  = mdl_robustppc_stan_spec,\n",
    "        data        = stan_datadictppc,\n",
    "        sample_file = ensure_dir('traces/trc_robustppc_stan/chain'),\n",
    "        model_name  = 'mdl_robustppc_stan',\n",
    "        iter        = 1000,\n",
    "        warmup      = 750, \n",
    "        chains      = 4, \n",
    "        n_jobs      = 2, \n",
    "        verbose     = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Don't print summary this time, since it now also contains 2593 estimates of y_ppc\n",
    "\n",
    "# print(mdl_robustppc_stan_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## similarly a terrible idea to simply call plot\n",
    "\n",
    "# mdl_robustppc_stan_fit.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract ppc from model fit object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ppc_pystan = mdl_robustppc_stan_fit.extract(pars='y_ppc', permuted=True, inc_warmup=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return array is datapoints * traces\n",
    "\n",
    "    for each datapoint:              2593x\n",
    "        use each trace value:        1000x\n",
    "            calc the posterior         10x\n",
    "            \n",
    "    creates 10,000 estimates for each data point (25,930,000 values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10, 2593)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppc_pystan['y_ppc'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2593, 10000)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_pystan = ppc_pystan['y_ppc'].reshape(1000*10, 2593).T\n",
    "yhat_pystan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deviance Information Criterion (DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Deviance Information Criterion](https://en.wikipedia.org/wiki/Deviance_information_criterion) (DIC) is a fairly unsophisticated method for comparing the deviance of likelihood across the sample traces of a model run. \n",
    "\n",
    "However, this simplicity apparently yields quite good results in a variety of cases, see the discussion worth reading in ([Speigelhalter et al 2014](http://onlinelibrary.wiley.com/doi/10.1111/rssb.12062/abstract))\n",
    "\n",
    "DIC has recently been added to PyMC3, so lets see what it tells us about our model fits. Lower numbers are better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OLS\n",
    "pm.stats.dic(model=mdl_ols, trace=trc_ols[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lasso\n",
    "pm.stats.dic(model=mdl_lasso, trace=trc_lasso[-7000::7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ridge\n",
    "pm.stats.dic(model=mdl_ridge, trace=trc_ridge[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observe:**\n",
    "\n",
    "+ All 3 values are quite similar! \n",
    "+ Interestingly, the Lasso has the highest (worst) DIC value, probably because I deliberately chose a suboptimal regularization parameter $\\lambda$ in order to favour the dropping of feature coefficients. This likely resulted in an _underfitted_ model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Predictive Checks (PPC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PPC is another model diagnostic we can easily use in PyMC3:\n",
    "\n",
    "1. For each datapoint (which naturally has a real value $y$), compute a vector of posterior predicted values $\\bf{\\hat{y}}$, using each value in the traces, using the model likelihood.\n",
    "2. Now you have a range of posterior predictions for each datapoint, which you can leave as a distribution or take summary statistics\n",
    "    1. If we take the mean summary statistic, then we can compute the **mean-squared-error (MSE)**\n",
    "    2. If we leave as a distribution, then we can compute 1d distributional differences such as the Kolmogorov–Smirnov test or Kullback–Leibler divergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I use the `sample_ppc()` function to:\n",
    "\n",
    "+ subsample 500 traces from the 1000 burned-in traces\n",
    "+ use each of the 500 subsampled trace values to create a model according to the model parameters\n",
    "+ and generate 50 samples of $\\hat{y}$ for each datapoint\n",
    "+ thereby getting 25,000 estimates of $\\hat{y}$ for each of the 2644 datapoints\n",
    "+ this is probably overkill\n",
    "+ but very quick to compute, so let's propogate the probability within the model...\n",
    "+ then I compute the MSE $\\frac{1}{n}\\sum_{i=1}^{i=n}(\\hat{y}_{i}-y_{i})^{2}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_ppc(trc, mdl, samples=500, size=50):\n",
    "    return pm.sample_ppc(trc_ols[-1000:], samples=500, model=mdl_ols, size=50)\n",
    "\n",
    "def compute_mse(df, ppc, ft_endog):\n",
    "    return np.sum((ppc['y'].mean(0).mean(0).T - df[[ft_endog]])**2)[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppc_ols = compute_ppc(trc_ols[-1000:], mdl_ols, 500, 50)\n",
    "ppc_lasso = compute_ppc(trc_lasso[-7000::7], mdl_lasso, 500, 50)\n",
    "ppc_ridge = compute_ppc(trc_ridge[-1000:], mdl_ridge, 500, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_mse = pd.DataFrame({'method':['OLS','Lasso','Ridge'], 'mse':np.zeros(3)})\n",
    "df_mse.set_index('method', inplace=True)\n",
    "\n",
    "for method, ppc in zip(['OLS','Lasso','Ridge'],[ppc_ols, ppc_lasso, ppc_ridge]):\n",
    "    df_mse.loc[method,'mse'] = compute_mse(dfs, ppc, ft_endog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observe:**\n",
    "\n",
    "+ The MSE for the models is extremely close: the Lasso and Ridge values are nearly identical and both represent about 99.92% of larger OLS value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have MSE anyway, lets calculate the (unadjusted) r-squared ($R^{2}$) value for each model. It's a ratio of the sum of squared errors for the model and the sum of squared errors for a hypothetical model that just predicts the mean of the dataset. \n",
    "\n",
    "$$R^{2} = 1 - \\frac{\\sum e_{model}^{2}}{\\sum e_{mean}^{2}}$$\n",
    "\n",
    "Ideally the $R^{2}$ lives in the range $[0,1]$, but in practice, it's quite easy for a model to perform arbitrily worse than the mean guess, particularly for oddly shaped data, resulting in a possible range (-inf, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_r2(df, ppc, ft_endog):\n",
    "    \n",
    "    sse_model = np.sum((ppc['y'].mean(0).mean(0).T - df[[ft_endog]])**2)[0]\n",
    "    sse_mean = np.sum((df[[ft_endog]] - df[ft_endog].mean())**2)[0]\n",
    "    \n",
    "    return 1 - (sse_model / sse_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for method, ppc in zip(['OLS','Lasso','Ridge'],[ppc_ols, ppc_lasso, ppc_ridge]):\n",
    "    df_mse.loc[method,'r2'] = compute_r2(dfs, ppc, ft_endog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observe:**\n",
    "\n",
    "+ Well, this ought not to be surprising given the MSE result: the $R^{2}$ results are nearly identical\n",
    "+ the $R^{2}$ for the OLS model is _marginally_ worse then the Lasso and the Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributional Check: Kolmogorov–Smirnov (KS) test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean values / MLEs are a clumsy way to summarise data, wasting lots of rich information present in our carefully gathered Bayesian samples.\n",
    "\n",
    "Instead of summarising to calcuate MSE and $R^{2}$, lets compare the distributions of the predicted values $\\hat{y}$ vs the actual values $y$\n",
    "\n",
    "I'll use the [Kolmogorov-Smirnov (KS) Test](https://en.wikipedia.org/wiki/Kolmogorov–Smirnov_test), specifically the 2-sample version, which lets us quantify the distance between the empirical distribution functions of two 'samples': the model predictions in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate the emprirical distribution functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ppc = pd.DataFrame({'observed': dfs[ft_endog]\n",
    "                       ,'ols': ppc_ols['y'].mean(0).mean(0).ravel()\n",
    "                       ,'lasso': ppc_lasso['y'].mean(0).mean(0).ravel()\n",
    "                       ,'ridge': ppc_ridge['y'].mean(0).mean(0).ravel()}\n",
    "                     , index=dfs.index)\n",
    "df_ppc = df_ppc[['observed','ols','lasso','ridge']]\n",
    "df_ppc_melt = pd.melt(df_ppc, var_name='method', value_name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boxplot the distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.factorplot(x='y', y='method', hue='method'\n",
    "        ,data=df_ppc_melt, kind='box', size=5, aspect=2, legend=False, showmeans=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lineplot the cumulative distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ppc_reordered = df_ppc.copy()\n",
    "\n",
    "for i, method in enumerate(['observed','ols','lasso','ridge']):\n",
    "     df_ppc_reordered[method] = ( (df_ppc[method].order()[::-1].cumsum() /\n",
    "                                 df_ppc[method].sum()).values )\n",
    "ax = df_ppc_reordered.plot(kind='line')\n",
    "_ = ax.set_ylim((0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observe:**\n",
    "\n",
    "+ I have a funny feeling we're going to see that the KS test is almost the same value for each of the methods..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform KS Test using `scipy.stats.ks_2samp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the [docs](http://docs.scipy.org/doc/scipy-0.16.0/reference/generated/scipy.stats.ks_2samp.html), this is a two-sided test for the null hypothesis that 2 independent samples are drawn from the same continuous distribution.\n",
    "\n",
    "If the K-S statistic is small or the p-value is high, then we cannot reject the hypothesis that the distributions of the two samples are the same. For my purposes here, I'm simply looking for mutual differences between the posterior predictive distibutions for `ols`, `lasso` and `ridge`, and their individual differences with the `observed` distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (a,b) in combinations(['observed','ols','lasso','ridge'],2):\n",
    "    print('\\n{} vs {}:'.format(a,b))\n",
    "    print(ks_2samp(df_ppc_reordered[a].values,df_ppc_reordered[b].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observe:**\n",
    "\n",
    "The first 3 results printed above show the difference between the `observed` distribution and the posterior predictive distribution for `ols`, `lasso`, and `ridge`\n",
    "\n",
    "+ The KS statistic is largest for `observed` vs `ridge`, which would suggest that the difference between these two distributions is smallest: the Ridge model fitted the data best.\n",
    "+ This is somewhat tenuous however, since the numbers are very very similar.\n",
    "\n",
    "The latter 3 results show the mutual differences between the three posterior distributions.\n",
    "\n",
    "+ In this case the KS statistic is very small and the p-values very high, indicating that we ought to treat the three posterior distributinos as the same.\n",
    "+ This serves to further qualify the above observation that differences with `observed` are minimal.\n",
    "\n",
    "We could read this as a good result: it's possible to create a Ridge regression that uses markedly less input data and achieves the same predictive results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set out to determine if there's anything strange about Volkswagen's NOx emissions results, and I'll freely admit to getting somewhat distracted by demonstrating some of the flexibility of PyMC3 and methods for evaluating results. \n",
    "\n",
    "There's two interesting clues in the Notebook though:\n",
    "\n",
    "+ The first is that the feature-value `mfr_owner_is_vw[T.True]` was selected by the Lasso model (both Frequentist and Bayesian versions) indicating that it has a non-negligible effect\n",
    "+ In the Ridge model (both versions) this feature-value coefficient receives a value quite far above zero, and indeed the vast majority (>>95%) of its distribution lies above zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**&copy; Applied AI Ltd 2016**  \n",
    "<a href='http://www.applied.ai'>applied.ai</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
